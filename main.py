import os
import requests
import json
from openai import OpenAI

# =========================================
# í™˜ê²½ ë³€ìˆ˜
# =========================================
NEWS_API_KEY = os.getenv("NEWS_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DISCORD_WEBHOOK = os.getenv("DISCORD_WEBHOOK")

MODEL_NAME = "gpt-4o-mini"

client = OpenAI(api_key=OPENAI_API_KEY)

# =========================================
# ë‰´ìŠ¤ ìˆ˜ì§‘
# =========================================
def fetch_news(query=None, country=None, language=None, limit=10):
    url = "https://newsapi.org/v2/top-headlines"

    params = {
        "pageSize": limit,
        "apiKey": NEWS_API_KEY,
    }

    if query:
        params["q"] = query
    if country:
        params["country"] = country
    if language:
        params["language"] = language

    response = requests.get(url, params=params)

    # HTTP ì—ëŸ¬ í™•ì¸
    if response.status_code != 200:
        print("HTTP ERROR:", response.status_code)
        print(response.text)
        return []

    data = response.json()

    # NewsAPI ë‚´ë¶€ ì—ëŸ¬ í™•ì¸
    if data.get("status") != "ok":
        print("NEWS API ERROR:", data)
        return []

    articles = data.get("articles", [])
    print("Fetched:", len(articles))
    return articles


# =========================================
# ì „ì²˜ë¦¬ (ì™„í™” ë²„ì „)
# =========================================
def preprocess_articles(articles):
    unique = {}

    for a in articles:
        title = (a.get("title") or "").strip()
        description = (a.get("description") or "").strip()
        content = (a.get("content") or "").strip()

        if not title:
            continue

        # description ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ content
        summary_text = description if description else content

        # ìµœì†Œ ê¸¸ì´ ì™„í™”
        if not summary_text or len(summary_text) < 10:
            continue

        # ì¤‘ë³µ ì œê±°
        if title in unique:
            continue

        unique[title] = {
            "title": title,
            "summary_text": summary_text,
            "url": a.get("url", "")
        }

    return list(unique.values())


# =========================================
# ì¤‘ìš” ê¸°ì‚¬ ì„ íƒ
# =========================================
def select_top_articles(articles, top_n=3):

    prompt = """
ë‹¤ìŒ ë‰´ìŠ¤ ì¤‘ IT/AI/ì‚°ì—…/ê°œë°œì ê´€ì ì—ì„œ ê°€ì¥ ì˜ë¯¸ ìˆëŠ” ê¸°ì‚¬ 3ê°œì˜ ë²ˆí˜¸ë§Œ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ë¼.
ë°˜ë“œì‹œ ì˜ˆ: [1,3,5] í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ë¼.
"""

    for i, a in enumerate(articles):
        prompt += f"\n[{i}] ì œëª©: {a['title']} ìš”ì•½: {a['summary_text']}"

    response = client.responses.create(
        model=MODEL_NAME,
        input=prompt,
        max_output_tokens=120,
        temperature=0.2
    )

    try:
        indices = json.loads(response.output_text.strip())
        print("Selected indices:", indices)
        return indices[:top_n]
    except Exception as e:
        print("Selection parse error:", e)
        return list(range(min(3, len(articles))))


# =========================================
# ìš”ì•½ + ë¶„ì„
# =========================================
def summarize_and_predict(article):

    prompt = f"""
ê¸°ì‚¬ ì œëª©:
{article['title']}

ê¸°ì‚¬ ë‚´ìš©:
{article['summary_text']}

1) í•µì‹¬ ìš”ì•½ (3~5ì¤„)
2) ì´ë²¤íŠ¸ ìœ í˜•
3) ì˜í–¥ ê¸°ì—…/ì‚°ì—…
4) ì£¼ê°€ ì˜í–¥ ë°©í–¥ ë° í™•ë¥ 
5) ë¦¬ìŠ¤í¬ ìš”ì¸
"""

    response = client.responses.create(
        model=MODEL_NAME,
        input=prompt,
        max_output_tokens=700,
        temperature=0.2
    )

    return response.output_text


# =========================================
# ë””ìŠ¤ì½”ë“œ ì „ì†¡
# =========================================
def send_to_discord(content):
    requests.post(DISCORD_WEBHOOK, json={"content": content})


# =========================================
# ë©”ì¸ ì‹¤í–‰
# =========================================
def main():

    # ğŸ” í•œêµ­/í•´ì™¸ ì¿¼ë¦¬ ë¶„ë¦¬
    kr_query = "ì¸ê³µì§€ëŠ¥ OR AI OR ìŠ¤íƒ€íŠ¸ì—… OR IT OR í”„ë¡œê·¸ë˜ë°"
    global_query = "AI OR startup OR programming OR technology"

    kr_news = fetch_news(query=kr_query, country="kr", limit=10)
    global_news = fetch_news(query=global_query, language="en", limit=10)

    print("KR raw:", len(kr_news))
    print("GLOBAL raw:", len(global_news))

    # 1ì°¨ ê²€ì¦
    if len(kr_news) == 0 and len(global_news) == 0:
        send_to_discord("NewsAPI ì‘ë‹µ ì—†ìŒ - API ë˜ëŠ” ì¿¼ë¦¬ í™•ì¸ í•„ìš”")
        return

    # ì „ì²˜ë¦¬
    articles = preprocess_articles(kr_news + global_news)

    print("After preprocess:", len(articles))

    # 2ì°¨ ê²€ì¦
    if len(articles) < 3:
        send_to_discord(f"ì „ì²˜ë¦¬ í›„ ê¸°ì‚¬ ë¶€ì¡±: {len(articles)}ê°œ")
        return

    # ì¤‘ìš” ê¸°ì‚¬ ì„ íƒ
    selected_indices = select_top_articles(articles)

    message = "ğŸ“Œ ì˜¤ëŠ˜ì˜ IT/AI í•µì‹¬ ë‰´ìŠ¤ TOP 3\n\n"

    for idx in selected_indices:
        if idx >= len(articles):
            continue

        article = articles[idx]
        result = summarize_and_predict(article)

        message += f"ğŸ”¹ {article['title']}\n"
        message += result
        message += "\n\n"

    send_to_discord(message)


if __name__ == "__main__":
    main()
